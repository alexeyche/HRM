{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7869a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the first 23 sentences for demo grammar:\n",
      "\n",
      "  S -> NP VP\n",
      "  NP -> Det N\n",
      "  PP -> P NP\n",
      "  VP -> 'slept' | 'saw' NP | 'walked' PP\n",
      "  Det -> 'the' | 'a'\n",
      "  N -> 'man' | 'park' | 'dog'\n",
      "  P -> 'in' | 'with'\n",
      "\n",
      "  1. the man slept\n",
      "  2. the man saw the man\n",
      "  3. the man saw the park\n",
      "  4. the man saw the dog\n",
      "  5. the man saw a man\n",
      "  6. the man saw a park\n",
      "  7. the man saw a dog\n",
      "  8. the man walked in the man\n",
      "  9. the man walked in the park\n",
      " 10. the man walked in the dog\n",
      " 11. the man walked in a man\n",
      " 12. the man walked in a park\n",
      " 13. the man walked in a dog\n",
      " 14. the man walked with the man\n",
      " 15. the man walked with the park\n",
      " 16. the man walked with the dog\n",
      " 17. the man walked with a man\n",
      " 18. the man walked with a park\n",
      " 19. the man walked with a dog\n",
      " 20. the park slept\n",
      " 21. the park saw the man\n",
      " 22. the park saw the park\n",
      " 23. the park saw the dog\n"
     ]
    }
   ],
   "source": [
    "from nltk.grammar import CFG\n",
    "from nltk.parse import generate\n",
    "\n",
    "demo_grammar = \"\"\"\n",
    "  S -> NP VP\n",
    "  NP -> Det N\n",
    "  PP -> P NP\n",
    "  VP -> 'slept' | 'saw' NP | 'walked' PP\n",
    "  Det -> 'the' | 'a'\n",
    "  N -> 'man' | 'park' | 'dog'\n",
    "  P -> 'in' | 'with'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "N = 23\n",
    "\n",
    "print(\"Generating the first %d sentences for demo grammar:\" % (N,))\n",
    "print(demo_grammar)\n",
    "grammar = CFG.fromstring(demo_grammar)\n",
    "for n, sent in enumerate(generate.generate(grammar, n=N), 1):\n",
    "    print(\"%3d. %s\" % (n, \" \".join(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287ba0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def demo():\n",
    "    \"\"\"\n",
    "    A demonstration of the shift-reduce parser.\n",
    "    \"\"\"\n",
    "\n",
    "    from nltk import CFG, parse\n",
    "\n",
    "    grammar = CFG.fromstring(\n",
    "        \"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N | Det N PP\n",
    "    VP -> V NP | V NP PP\n",
    "    PP -> P NP\n",
    "    NP -> 'I'\n",
    "    N -> 'man' | 'park' | 'telescope' | 'dog'\n",
    "    Det -> 'the' | 'a'\n",
    "    P -> 'in' | 'with'\n",
    "    V -> 'saw'\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    sent = \"I saw a man in the park\".split()\n",
    "\n",
    "    parser = parse.ShiftReduceParser(grammar, trace=2)\n",
    "    for p in parser.parse(sent):\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4359fb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'I saw a man in the park'\n",
      "    [ * I saw a man in the park]\n",
      "  S [ 'I' * saw a man in the park]\n",
      "  R [ NP * saw a man in the park]\n",
      "  S [ NP 'saw' * a man in the park]\n",
      "  R [ NP V * a man in the park]\n",
      "  S [ NP V 'a' * man in the park]\n",
      "  R [ NP V Det * man in the park]\n",
      "  S [ NP V Det 'man' * in the park]\n",
      "  R [ NP V Det N * in the park]\n",
      "  R [ NP V NP * in the park]\n",
      "  R [ NP VP * in the park]\n",
      "  R [ S * in the park]\n",
      "  S [ S 'in' * the park]\n",
      "  R [ S P * the park]\n",
      "  S [ S P 'the' * park]\n",
      "  R [ S P Det * park]\n",
      "  S [ S P Det 'park' * ]\n",
      "  R [ S P Det N * ]\n",
      "  R [ S P NP * ]\n",
      "  R [ S PP * ]\n"
     ]
    }
   ],
   "source": [
    "demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "760f21f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw John with a dog with my cookie\n",
      "['I', 'saw', 'John', 'with', 'a', 'dog', 'with', 'my', 'cookie']\n",
      "\n",
      "|. I  .saw .John.with. a  .dog .with. my .cook.|\n",
      "Leaf Init Rule:\n",
      "|[----]    .    .    .    .    .    .    .    .| [0:1] 'I'\n",
      "|.    [----]    .    .    .    .    .    .    .| [1:2] 'saw'\n",
      "|.    .    [----]    .    .    .    .    .    .| [2:3] 'John'\n",
      "|.    .    .    [----]    .    .    .    .    .| [3:4] 'with'\n",
      "|.    .    .    .    [----]    .    .    .    .| [4:5] 'a'\n",
      "|.    .    .    .    .    [----]    .    .    .| [5:6] 'dog'\n",
      "|.    .    .    .    .    .    [----]    .    .| [6:7] 'with'\n",
      "|.    .    .    .    .    .    .    [----]    .| [7:8] 'my'\n",
      "|.    .    .    .    .    .    .    .    [----]| [8:9] 'cookie'\n",
      "Top Down Init Rule:\n",
      "|>    .    .    .    .    .    .    .    .    .| [0:0] S  -> * NP VP\n",
      "\n",
      "* Processing queue: 0 \n",
      "\n",
      "Predictor Rule:\n",
      "|>    .    .    .    .    .    .    .    .    .| [0:0] NP -> * NP PP\n",
      "|>    .    .    .    .    .    .    .    .    .| [0:0] NP -> * Det Noun\n",
      "|>    .    .    .    .    .    .    .    .    .| [0:0] NP -> * 'I'\n",
      "\n",
      "* Processing queue: 1 \n",
      "\n",
      "Scanner Rule:\n",
      "|[----]    .    .    .    .    .    .    .    .| [0:1] NP -> 'I' *\n",
      "Completer Rule:\n",
      "|[---->    .    .    .    .    .    .    .    .| [0:1] S  -> NP * VP\n",
      "|[---->    .    .    .    .    .    .    .    .| [0:1] NP -> NP * PP\n",
      "Predictor Rule:\n",
      "|.    >    .    .    .    .    .    .    .    .| [1:1] VP -> * VP PP\n",
      "|.    >    .    .    .    .    .    .    .    .| [1:1] VP -> * Verb NP\n",
      "|.    >    .    .    .    .    .    .    .    .| [1:1] VP -> * Verb\n",
      "Predictor Rule:\n",
      "|.    >    .    .    .    .    .    .    .    .| [1:1] Verb -> * 'saw'\n",
      "\n",
      "* Processing queue: 2 \n",
      "\n",
      "Scanner Rule:\n",
      "|.    [----]    .    .    .    .    .    .    .| [1:2] Verb -> 'saw' *\n",
      "Completer Rule:\n",
      "|.    [---->    .    .    .    .    .    .    .| [1:2] VP -> Verb * NP\n",
      "|.    [----]    .    .    .    .    .    .    .| [1:2] VP -> Verb *\n",
      "Completer Rule:\n",
      "|[---------]    .    .    .    .    .    .    .| [0:2] S  -> NP VP *\n",
      "|.    [---->    .    .    .    .    .    .    .| [1:2] VP -> VP * PP\n",
      "Predictor Rule:\n",
      "|.    .    >    .    .    .    .    .    .    .| [2:2] NP -> * NP PP\n",
      "|.    .    >    .    .    .    .    .    .    .| [2:2] NP -> * Det Noun\n",
      "|.    .    >    .    .    .    .    .    .    .| [2:2] NP -> * 'John'\n",
      "\n",
      "* Processing queue: 3 \n",
      "\n",
      "Scanner Rule:\n",
      "|.    .    [----]    .    .    .    .    .    .| [2:3] NP -> 'John' *\n",
      "Completer Rule:\n",
      "|.    [---------]    .    .    .    .    .    .| [1:3] VP -> Verb NP *\n",
      "|.    .    [---->    .    .    .    .    .    .| [2:3] NP -> NP * PP\n",
      "Predictor Rule:\n",
      "|.    .    .    >    .    .    .    .    .    .| [3:3] PP -> * 'with' NP\n",
      "Completer Rule:\n",
      "|[--------------]    .    .    .    .    .    .| [0:3] S  -> NP VP *\n",
      "|.    [--------->    .    .    .    .    .    .| [1:3] VP -> VP * PP\n",
      "\n",
      "* Processing queue: 4 \n",
      "\n",
      "Scanner Rule:\n",
      "|.    .    .    [---->    .    .    .    .    .| [3:4] PP -> 'with' * NP\n",
      "Predictor Rule:\n",
      "|.    .    .    .    >    .    .    .    .    .| [4:4] NP -> * NP PP\n",
      "|.    .    .    .    >    .    .    .    .    .| [4:4] NP -> * Det Noun\n",
      "Predictor Rule:\n",
      "|.    .    .    .    >    .    .    .    .    .| [4:4] Det -> * 'a'\n",
      "\n",
      "* Processing queue: 5 \n",
      "\n",
      "Scanner Rule:\n",
      "|.    .    .    .    [----]    .    .    .    .| [4:5] Det -> 'a' *\n",
      "Completer Rule:\n",
      "|.    .    .    .    [---->    .    .    .    .| [4:5] NP -> Det * Noun\n",
      "Predictor Rule:\n",
      "|.    .    .    .    .    >    .    .    .    .| [5:5] Noun -> * 'dog'\n",
      "\n",
      "* Processing queue: 6 \n",
      "\n",
      "Scanner Rule:\n",
      "|.    .    .    .    .    [----]    .    .    .| [5:6] Noun -> 'dog' *\n",
      "Completer Rule:\n",
      "|.    .    .    .    [---------]    .    .    .| [4:6] NP -> Det Noun *\n",
      "Completer Rule:\n",
      "|.    .    .    [--------------]    .    .    .| [3:6] PP -> 'with' NP *\n",
      "|.    .    .    .    [--------->    .    .    .| [4:6] NP -> NP * PP\n",
      "Predictor Rule:\n",
      "|.    .    .    .    .    .    >    .    .    .| [6:6] PP -> * 'with' NP\n",
      "Completer Rule:\n",
      "|.    .    [-------------------]    .    .    .| [2:6] NP -> NP PP *\n",
      "|.    [------------------------]    .    .    .| [1:6] VP -> VP PP *\n",
      "Completer Rule:\n",
      "|[-----------------------------]    .    .    .| [0:6] S  -> NP VP *\n",
      "|.    [------------------------>    .    .    .| [1:6] VP -> VP * PP\n",
      "Completer Rule:\n",
      "|.    [------------------------]    .    .    .| [1:6] VP -> Verb NP *\n",
      "|.    .    [------------------->    .    .    .| [2:6] NP -> NP * PP\n",
      "Completer Rule:\n",
      "|[-----------------------------]    .    .    .| [0:6] S  -> NP VP *\n",
      "|.    [------------------------>    .    .    .| [1:6] VP -> VP * PP\n",
      "\n",
      "* Processing queue: 7 \n",
      "\n",
      "Scanner Rule:\n",
      "|.    .    .    .    .    .    [---->    .    .| [6:7] PP -> 'with' * NP\n",
      "Predictor Rule:\n",
      "|.    .    .    .    .    .    .    >    .    .| [7:7] NP -> * NP PP\n",
      "|.    .    .    .    .    .    .    >    .    .| [7:7] NP -> * Det Noun\n",
      "Predictor Rule:\n",
      "|.    .    .    .    .    .    .    >    .    .| [7:7] Det -> * 'my'\n",
      "\n",
      "* Processing queue: 8 \n",
      "\n",
      "Scanner Rule:\n",
      "|.    .    .    .    .    .    .    [----]    .| [7:8] Det -> 'my' *\n",
      "Completer Rule:\n",
      "|.    .    .    .    .    .    .    [---->    .| [7:8] NP -> Det * Noun\n",
      "Predictor Rule:\n",
      "|.    .    .    .    .    .    .    .    >    .| [8:8] Noun -> * 'cookie'\n",
      "\n",
      "* Processing queue: 9 \n",
      "\n",
      "Scanner Rule:\n",
      "|.    .    .    .    .    .    .    .    [----]| [8:9] Noun -> 'cookie' *\n",
      "Completer Rule:\n",
      "|.    .    .    .    .    .    .    [---------]| [7:9] NP -> Det Noun *\n",
      "Completer Rule:\n",
      "|.    .    .    .    .    .    [--------------]| [6:9] PP -> 'with' NP *\n",
      "|.    .    .    .    .    .    .    [--------->| [7:9] NP -> NP * PP\n",
      "Completer Rule:\n",
      "|.    .    .    .    [------------------------]| [4:9] NP -> NP PP *\n",
      "|.    [---------------------------------------]| [1:9] VP -> VP PP *\n",
      "|.    .    [----------------------------------]| [2:9] NP -> NP PP *\n",
      "Completer Rule:\n",
      "|.    [---------------------------------------]| [1:9] VP -> Verb NP *\n",
      "|.    .    [---------------------------------->| [2:9] NP -> NP * PP\n",
      "Completer Rule:\n",
      "|[============================================]| [0:9] S  -> NP VP *\n",
      "|.    [--------------------------------------->| [1:9] VP -> VP * PP\n",
      "Completer Rule:\n",
      "|[============================================]| [0:9] S  -> NP VP *\n",
      "|.    [--------------------------------------->| [1:9] VP -> VP * PP\n",
      "Completer Rule:\n",
      "|.    .    .    [-----------------------------]| [3:9] PP -> 'with' NP *\n",
      "|.    .    .    .    [------------------------>| [4:9] NP -> NP * PP\n",
      "Completer Rule:\n",
      "|.    .    [----------------------------------]| [2:9] NP -> NP PP *\n",
      "|.    [---------------------------------------]| [1:9] VP -> VP PP *\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (Verb saw)\n",
      "    (NP\n",
      "      (NP (NP John) (PP with (NP (Det a) (Noun dog))))\n",
      "      (PP with (NP (Det my) (Noun cookie))))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (Verb saw)\n",
      "    (NP\n",
      "      (NP John)\n",
      "      (PP\n",
      "        with\n",
      "        (NP\n",
      "          (NP (Det a) (Noun dog))\n",
      "          (PP with (NP (Det my) (Noun cookie))))))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog))))\n",
      "    (PP with (NP (Det my) (Noun cookie)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog)))))\n",
      "    (PP with (NP (Det my) (Noun cookie)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (Verb saw) (NP John))\n",
      "    (PP\n",
      "      with\n",
      "      (NP\n",
      "        (NP (Det a) (Noun dog))\n",
      "        (PP with (NP (Det my) (Noun cookie)))))))\n",
      "Time: 0.0021579579915851355\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "from nltk.parse import EarleyChartParser\n",
    "\n",
    "\n",
    "def demo(\n",
    "    print_times=True,\n",
    "    print_grammar=False,\n",
    "    print_trees=True,\n",
    "    trace=2,\n",
    "    sent=\"I saw John with a dog with my cookie\",\n",
    "    numparses=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    A demonstration of the Earley parsers.\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import time\n",
    "\n",
    "    from nltk.parse.chart import demo_grammar\n",
    "\n",
    "    # The grammar for ChartParser and SteppingChartParser:\n",
    "    grammar = demo_grammar()\n",
    "    if print_grammar:\n",
    "        print(\"* Grammar\")\n",
    "        print(grammar)\n",
    "\n",
    "    # Tokenize the sample sentence.\n",
    "    print(\"* Sentence:\")\n",
    "    print(sent)\n",
    "    tokens = sent.split()\n",
    "    print(tokens)\n",
    "    print()\n",
    "\n",
    "    # Do the parsing.\n",
    "    earley = EarleyChartParser(grammar, trace=trace)\n",
    "    t = perf_counter()\n",
    "    chart = earley.chart_parse(tokens)\n",
    "    parses = list(chart.parses(grammar.start()))\n",
    "    t = perf_counter() - t\n",
    "\n",
    "    # Print results.\n",
    "    if numparses:\n",
    "        assert len(parses) == numparses, \"Not all parses found\"\n",
    "    if print_trees:\n",
    "        for tree in parses:\n",
    "            print(tree)\n",
    "    else:\n",
    "        print(\"Nr trees:\", len(parses))\n",
    "    if print_times:\n",
    "        print(\"Time:\", t)\n",
    "\n",
    "demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea9c2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.grammar import Nonterminal\n",
    "\n",
    "def viable_next_tokens(chart, position, grammar):\n",
    "    \"\"\"\n",
    "    Given a chart and the current position in the input,\n",
    "    return the set of terminals that could appear next.\n",
    "    \"\"\"\n",
    "    candidates = set()\n",
    "    for edge in chart.select(end=position):\n",
    "        # edge is something like A -> α • β, [i:j]\n",
    "        next_sym = edge.nextsym()\n",
    "        if next_sym is None:\n",
    "            continue\n",
    "        if isinstance(next_sym, Nonterminal):\n",
    "            # Expand FIRST set of this nonterminal\n",
    "            for prod in grammar.productions(lhs=next_sym):\n",
    "                first = prod.rhs()[0]\n",
    "                if isinstance(first, str):  # terminal\n",
    "                    candidates.add(first)\n",
    "        else:\n",
    "            # Directly a terminal\n",
    "            candidates.add(next_sym)\n",
    "    return candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd0f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw John with a cookie with my dog with John\n",
      "['I', 'saw', 'John', 'with', 'a', 'cookie', 'with', 'my', 'dog', 'with', 'John']\n",
      "\n",
      "At position 0, expected tokens: {'John', 'the', 'I', 'my', 'a'}\n",
      "At position 1, expected tokens: {'saw', 'ate', 'with'}\n",
      "At position 2, expected tokens: {'John', 'the', 'with', 'I', 'my', 'a'}\n",
      "At position 3, expected tokens: {'with'}\n",
      "At position 4, expected tokens: {'John', 'the', 'I', 'my', 'a'}\n",
      "At position 5, expected tokens: {'dog', 'cookie'}\n",
      "At position 6, expected tokens: {'with'}\n",
      "At position 7, expected tokens: {'John', 'the', 'I', 'my', 'a'}\n",
      "At position 8, expected tokens: {'dog', 'cookie'}\n",
      "At position 9, expected tokens: {'with'}\n",
      "At position 10, expected tokens: {'John', 'the', 'I', 'my', 'a'}\n",
      "At position 11, expected tokens: {'with'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.chart import demo_grammar\n",
    "\n",
    "# The grammar for ChartParser and SteppingChartParser:\n",
    "grammar = demo_grammar()\n",
    "\n",
    "sent = \"I saw John with a cookie with my dog with John\"\n",
    "\n",
    "# Tokenize the sample sentence.\n",
    "print(\"* Sentence:\")\n",
    "print(sent)\n",
    "tokens = sent.split()\n",
    "print(tokens)\n",
    "print()\n",
    "\n",
    "# Do the parsing.\n",
    "earley = EarleyChartParser(grammar)\n",
    "\n",
    "chart = earley.chart_parse(tokens)\n",
    "for pos in range(len(tokens) + 1):\n",
    "    print(f\"At position {pos}, expected tokens:\", viable_next_tokens(chart, pos, grammar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ce30e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IncrementalChart' object has no attribute 'e'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchart\u001b[49m\u001b[43m.\u001b[49m\u001b[43me\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'IncrementalChart' object has no attribute 'e'"
     ]
    }
   ],
   "source": [
    "chart.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304993b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
